{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "\n",
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Chapter 4: Full Robot Simulatiom\n",
    "Welcome to the fourth day of our hands-on course!\n",
    "Today, you will focus on wirting the whole roboter plan and understand more of the basic concepts within pycram.\n",
    "### Goal\n",
    "By the end of the session, you will have successfully eecuted robot control programm.\n"
   ],
   "id": "39e8274f8061eaa9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Getting Started\n",
    "First we will load all the Libaries and spawn the Kitchen and Robot, as we did in earlier examples."
   ],
   "id": "6f22a9fe1531dc2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pycram.external_interfaces.ik import request_ik\n",
    "from pycram.plan_failures import IKError\n",
    "from pycram.ros.tf_broadcaster import TFBroadcaster\n",
    "from pycram.ros.viz_marker_publisher import VizMarkerPublisher, AxisMarkerPublisher, CostmapPublisher\n",
    "from pycram.utils import _apply_ik\n",
    "from pycram.worlds.bullet_world import BulletWorld\n",
    "from pycram.designators.action_designator import *\n",
    "from pycram.designators.location_designator import *\n",
    "from pycram.designators.object_designator import *\n",
    "from pycram.datastructures.enums import ObjectType, WorldMode, TorsoState\n",
    "from pycram.datastructures.pose import Pose, Transform\n",
    "from pycram.process_module import simulated_robot, with_simulated_robot\n",
    "from pycram.object_descriptors.urdf import ObjectDescription\n",
    "from pycram.world_concepts.world_object import Object\n",
    "from pycram.datastructures.dataclasses import Color\n",
    "\n",
    "extension = ObjectDescription.get_file_extension()\n",
    "\n",
    "world = BulletWorld(WorldMode.DIRECT)\n",
    "world.allow_publish_debug_poses = True\n",
    "viz = VizMarkerPublisher()\n",
    "tf = TFBroadcaster()\n",
    "\n",
    "robot_name = \"pr2\"\n",
    "robot = Object(robot_name, ObjectType.ROBOT, f\"{robot_name}{extension}\", pose=Pose([1, 2, 0]))\n",
    "\n",
    "apartment = Object(\"apartment\", ObjectType.ENVIRONMENT, f\"apartment-small{extension}\")\n",
    "milk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([0.5, 2.5, 1]))\n",
    "milk.color = Color(0, 0, 1, 1)\n",
    "milk_desig = BelieveObject(names=[\"milk\"])\n",
    "robot_desig = BelieveObject(names=[robot_name])\n",
    "apartment_desig = BelieveObject(names=[\"apartment\"])"
   ],
   "id": "2ad8cd95305d1652"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Start we we left off with detecting the milk in the open fridge:"
   ],
   "id": "f80ebdb34821e5b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with simulated_robot:\n",
    "    poseHard = Pose([1.3, 2.7, 0], [0, 0, 1, 0])\n",
    "    NavigateAction([poseHard]).resolve().perform()\n",
    "\n",
    "    ParkArmsAction([Arms.BOTH]).resolve().perform()\n",
    "\n",
    "    MoveTorsoAction([TorsoState.HIGH]).resolve().perform()\n",
    "    handle_desig = ObjectPart(names=[\"handle_cab3_door_top\"], part_of=apartment_desig.resolve())\n",
    "    closed_location, opened_location = AccessingLocation(handle_desig=handle_desig.resolve(),\n",
    "                                                         robot_desig=robot_desig.resolve()).resolve()\n",
    "    OpenAction(object_designator_description=handle_desig, arms=[closed_location.arms[0]],\n",
    "               start_goal_location=[closed_location, opened_location]).resolve().perform()\n",
    "    \n",
    "    LookAtAction(targets=[milk_desig.resolve().pose]).resolve().perform()\n",
    "    obj_desig = DetectAction(milk_desig).resolve().perform()"
   ],
   "id": "ff15ae72ea3d0974",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now what is left todo: Pick up the milk, Transport the milk, Place the milk close the fridge. This might sound for a human quite simple but for a robot controll programm this can be very heavy. Think about what knowledge youd need in order to be able to pick the milk. You will need knowledge on how to move your arm, where to move your arm how much foce youd need for in order to held the mmilk properly, is the milk full half full or not depending on that youd need different velocity / energy to pick it up. Is the milk open or closed, depending on that youd might need a different way to carry it to not spill anthing,  how to move to safely place the milk, where to place the milk and so on.\n",
    "Within this tutorial we will not cover any possibilities and or limitation since our pycram world is a rapid fire simulation this means it is designed to have schemantic understanding of a robot controll programm like a cognitive architecture should, but to try out new plans the robot is moving faster then in a photrelsstic environemnt and we also teleport the robot instead of moving it along a path to safe time.\n",
    "\n",
    "But what we will cover is: \n",
    "     1. Parking both arms for initial positioning.\n",
    "      2. Determining the appropriate grasp based on object type.\n",
    "      3. Finding a reachable pose for the robot to pick up the object with the designated arm.\n",
    "       4. Navigating to the pick-up pose, performing the pick-up, and then parking arms again.\n",
    "       5. Resolving a place location reachable by the robot to place the object.\n",
    "       6. Navigating to the place location, performing the placement, and parking arms post-transport.\n",
    "\n",
    "#### The Grasp\n",
    "The Grasp it a tricky part in every robot controll programm. DEpending on where the perception system detected the object the object orientation can be very different. We want to be able to tell the robot \" pick up the milk from front\" or \"from top\" or other dirention. Natevily we want front top etc in a form that we human can use iteasily, for example nno matter how the milk is perceied in the fridge, the robot should always approach the object from front side of the fridge, if you rethink this to be on the other side of the kithn we have a orienttion problem. To overcome this axis problem we developed a calculate_object_face fucntion which takes an object as a parameter and then through rotation matri and where the robot stands calculates how the object is face dtowards the robot.\n",
    "<details>\n",
    "\n",
    "<summary>Click here for the math behind calculate_object:faces</summary>\n",
    "\n",
    "```python\n",
    "from pycram.designators.action_designator import DetectAction, LookAtAction, ParkArmsAction, NavigateAction\n",
    "from pycram.designators.object_designator import BelieveObject\n",
    "from pycram.datastructures.enums import Arms\n",
    "from pycram.process_module import simulated_robot\n",
    "from pycram.datastructures.pose import Pose\n",
    "\n",
    "milk_desig = BelieveObject(names=[\"milk\"])\n",
    "\n",
    "with simulated_robot:\n",
    "    ParkArmsAction([Arms.BOTH]).resolve().perform()\n",
    "\n",
    "    NavigateAction([Pose([0, 1, 0], [0, 0, 0, 1])]).resolve().perform()\n",
    "\n",
    "    LookAtAction(targets=[milk_desig.resolve().pose]).resolve().perform()\n",
    "\n",
    "    obj_desig = DetectAction(milk_desig).resolve().perform()\n",
    "\n",
    "    print(obj_desig)\n",
    "```\n",
    "</details>\n",
    "\n",
    "we will be left off witha determined grasp by the faced rotation of the object\n",
    "then we will use the CostmapLocation to find a place where the robot can stand to pick up the milk\n",
    "#exercise: use the robot_desig the obj_desig an arm of your choice  and the detrmined grasp to find out a suitable pose with CostmapLocation"
   ],
   "id": "22addccd35f13baa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5cb49ae15275a651"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "## add your code here"
   ],
   "id": "383c3a59000a5913",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<details>\n",
    "\n",
    "<summary>Click here for the Solution.</summary>\n",
    "\n",
    "```python\n",
    "with simulated_robot:\n",
    "   grasp = calculate_object_faces(self.object_designator)[0]\n",
    "\n",
    "        pickup_loc = CostmapLocation(\n",
    "            target=self.object_designator,\n",
    "            reachable_for=robot_desig.resolve(),\n",
    "            reachable_arm=self.arm,\n",
    "            used_grasps=[grasp]\n",
    "        )\n",
    "```\n",
    "</details>\n",
    "You will be left off with a list of possible pick up location now we will iter over those poses in location to check if the pose is reachable for the arm.\n",
    "\n",
    "´´´python\n",
    "  pickup_pose = next((pose for pose in pickup_loc if self.arm in pose.reachable_arms), None)\n",
    "        if not pickup_pose:\n",
    "            raise ObjectUnfetchable(\n",
    "                f\"No reachable pose found for the robot to grasp the object: {self.object_designator} with arm: {self.arm}\"\n",
    "            )\n",
    " ´´´\n",
    " After that we Navigate to the found pose and to a PickUpAction. This pickupaaction takes the object designator the arm and the earlier determined grasp as parameters.\n",
    " "
   ],
   "id": "7447f776722e8d0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "## add your code here",
   "id": "dcacb59addf105",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "<details>\n",
    "\n",
    "<summary>Click here for the Solution.</summary>\n",
    "\n",
    "```python\n",
    "with simulated_robot:\n",
    "\n",
    "    PickUpAction(spoon_desig, [Arms.LEFT], [Grasp.TOP]).resolve().perform()\n",
    "\n",
    "```\n",
    "</details>\n",
    "\n",
    "\n",
    "Then we again use the Costmap in order to find a place to stand to place the objec ton a given pose. we hope you undertood how much information a robot needs to fullfill a basic pick and place order scenariou. We already put this all into a TransportAction which can be used by u.\n",
    "Now your task is to write the full plan with trransporting in and closing the fridge. The milkplace pose is:     milk_target_pose = Pose([5.34, 3.55, 0.8])\n"
   ],
   "id": "8d98dccacc1bdef4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "    milk_target_pose = Pose([5.34, 3.55, 0.8])\n",
   "id": "7e2f81fee95966c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "766b64311f711696"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5db6a7cc124176d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "## add your code here\n",
   "id": "cd9f2322ef4fa180",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<details>\n",
    "\n",
    "<summary>Click here for the Solution.</summary>\n",
    "\n",
    "```python\n",
    "with simulated_robot:\n",
    "    poseHard = Pose([1.3, 2.7, 0], [0, 0, 1, 0])\n",
    "    NavigateAction([poseHard]).resolve().perform()\n",
    "\n",
    "    ParkArmsAction([Arms.BOTH]).resolve().perform()\n",
    "\n",
    "    MoveTorsoAction([TorsoState.HIGH]).resolve().perform()\n",
    "    handle_desig = ObjectPart(names=[\"handle_cab3_door_top\"], part_of=apartment_desig.resolve())\n",
    "    closed_location, opened_location = AccessingLocation(handle_desig=handle_desig.resolve(),\n",
    "                                                         robot_desig=robot_desig.resolve()).resolve()\n",
    "    OpenAction(object_designator_description=handle_desig, arms=[closed_location.arms[0]],\n",
    "               start_goal_location=[closed_location, opened_location]).resolve().perform()\n",
    "\n",
    "    LookAtAction(targets=[milk_desig.resolve().pose]).resolve().perform()\n",
    "    obj_desig = DetectAction(milk_desig).resolve().perform()\n",
    "    milk_target_pose = Pose([5.34, 3.55, 0.8])\n",
    "    ParkArmsAction([Arms.BOTH]).resolve().perform()\n",
    "    MoveTorsoAction([TorsoState.HIGH]).resolve().perform()\n",
    "    TransportAction(obj_desig, [Arms.LEFT], [milk_target_pose]).resolve().perform()\n",
    "```\n",
    "</details>\n"
   ],
   "id": "cb8ab0d9a2fa7df1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now we have our first full transporting plan! Of course we are missing a lot of cognitive enabled stuff here but for the basic understanding this is really good already.\n",
    "What is missing btu yet important?\n",
    "For example failure handling. Failure handling nto only makes the robot more robust but it also makes us rethink but a plan of a robot controll system actual has to face. in order to design a genrelized failure handling ur controll programm must be semantic understood and open withut any hidden infomration to for example, retry, replan, transofrm, or react differnt to failures.\n",
    "\n",
    "Another concept would be learning from memories. so we log everything that th robot did in the past and can replay revisit this to inform the robot abut what he is doing wrong this time, you can find more on this in our extra materials for chapter 6.\n",
    "\n",
    "\n",
    "More physical udnerstanding\n",
    "as described above the physical understanding is kinda cheated in this simulation, so how would be do this.\n",
    "\n",
    "INSERT MULTIVERSE"
   ],
   "id": "d83c1d2ff7e1f6fc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
